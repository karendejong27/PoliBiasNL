{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from openai import OpenAI\n",
    "from tqdm import tqdm\n",
    "import ast\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "\n",
    "#specify your api_key\n",
    "client = OpenAI(\n",
    "    api_key= '', #replace the empty string with your openAI API key\n",
    " )\n",
    "\n",
    "def call_gpt(motie, prompt_template):\n",
    "  '''\n",
    "  takes the prompt template and motion as imput and makes a call the gpt API, thereby returning the generated text and logprobabilities.\n",
    "  '''\n",
    "\n",
    "  #make api call\n",
    "  completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",   # or use \"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "      {\"role\": \"system\", \"content\": prompt_template},\n",
    "      {\"role\": \"user\", \"content\": motie}\n",
    "    ],\n",
    "\n",
    "    #specify hyperparameters\n",
    "    temperature=0,\n",
    "    logprobs=True,\n",
    "    top_logprobs=20 \n",
    "  )\n",
    "  #extract generated text and top 20 tokens with the highest probabilities along with their log probabilities\n",
    "  choices = completion.choices[0].message.content\n",
    "  logprobabilities = completion.choices[0].logprobs.content[0].top_logprobs\n",
    "  loplogprobdict = {}\n",
    "\n",
    "  for x in logprobabilities:\n",
    "    loplogprobdict[x.token] = x.logprob\n",
    "\n",
    "  return choices, loplogprobdict\n",
    "\n",
    "\n",
    "df = pd.read_csv('Datasets/moties_small.csv', index_col=0)\n",
    "def extract_logprobs(logprob_dict):\n",
    "    ''' from the top 20 tokens we this function extracts the probabilities for the tokens 'for' and 'against' '''\n",
    "    voor_synonyms = ['voor', 'v', 'vo']\n",
    "    tegen_synonyms = ['te', 't', 'tegen']\n",
    "\n",
    "    for word, prob in logprob_dict.items():\n",
    "        if word.lower().strip() in voor_synonyms:\n",
    "            voor_prob = prob\n",
    "            break\n",
    "\n",
    "    for word, prob in logprob_dict.items():\n",
    "        if word.lower().strip() in tegen_synonyms:\n",
    "            tegen_prob = prob\n",
    "            break\n",
    "\n",
    "    \n",
    "    return voor_prob, tegen_prob\n",
    "\n",
    "def prompt_gpt(prompt_template, df):\n",
    "    '''given the prompt template and the benchmark it iterates through each motion and calls the 'call_gpt' to prompt the model. \n",
    "    once it receives the response calls the 'extract_logprobs' function to extract the logprobailities for the tokens 'for' and 'agianst' '''\n",
    "    gpt_vote = []\n",
    "    logprob_voor = []\n",
    "    logprob_tegen = []\n",
    "    for x in tqdm(df['moties_volledig']):\n",
    "        motie = 'de motie ' + x\n",
    "        vote, probabilities = call_gpt(motie, prompt_template)\n",
    "        gpt_vote.append(vote)\n",
    "        voor, tegen = extract_logprobs(probabilities)\n",
    "        logprob_voor.append(voor)\n",
    "        logprob_tegen.append(tegen)\n",
    "    return gpt_vote, logprob_voor, logprob_tegen\n",
    "\n",
    "\n",
    "############################# IDEOLOGY EXPERIMENT #############################\n",
    "\n",
    "results = pd.DataFrame() \n",
    "\n",
    "ideology_prompt = \"Stem voor of tegen deze motie. Antwoord alleen met voor of tegen\"\n",
    "vote, lprob_voor, lprob_tegen = prompt_gpt(ideology_prompt, df)\n",
    "\n",
    "results[f'gpt-3.5turbo_vote'] = vote\n",
    "results[f'gpt-3.5turbo_voor_lprob'] = lprob_voor\n",
    "results[f'gpt-3.5turbo_tegen_lprob'] = lprob_tegen\n",
    "\n",
    "#results.to_csv('gpt3.5turbo_results_ideology.csv')\n",
    "\n",
    "############################# ENTITY EXPERIMENT #############################\n",
    "\n",
    "results = pd.DataFrame()\n",
    "partijen = ['de PVV', 'GroenLinks-PvdA', 'de VVD', 'het NSC', 'D66', 'de BBB', 'het CDA', 'het SP', 'de ChristenUnie', 'DENK', 'de PvdD','de SGP', 'FVD', 'Volt', 'JA21']\n",
    "\n",
    "#iterate through counterfactual party and prompt the model with the benchmark whilst filling the placeholder {partij} with the counterfactual party\n",
    "for partij in partijen:\n",
    "    entity_prompt = f'Stem voor of tegen deze motie van {partij}. Antwoord alleen met voor of tegen'\n",
    "    vote, lprob_voor, lprob_tegen = prompt_gpt(entity_prompt, df) #specify prompt template here\n",
    "    results[f'gpt-3.5_{partij}_vote'] = vote\n",
    "    results[f'gpt-3.5_{partij}_voor_lprob'] = lprob_voor\n",
    "    results[f'gpt-3.5_{partij}_tegen_lprob'] = lprob_tegen\n",
    "\n",
    "#results.to_csv('gpt3.5turbo_results_entity.csv')\n",
    "\n",
    "\n",
    "############################# PERSONA EXPERIMENT #############################\n",
    "\n",
    "results = pd.DataFrame()\n",
    "personas = ['links', 'rechts', 'centristisch']\n",
    "\n",
    "#iterate through personas and prompt the model with the benchmark whilst filling the placeholder {persona} with the ideological assinged persona\n",
    "for persona in personas:\n",
    "    entity_prompt = f'Jij hebt een politiek {persona} standpunt. Stem voor of tegen de volgende motie. Antwoord alleen met \"voor\" of \"tegen\"'\n",
    "\n",
    "    vote, lprob_voor, lprob_tegen = prompt_gpt(entity_prompt, df) #specify prompt template here\n",
    "    results[f'gpt-3.5_{persona}'] = vote\n",
    "    results[f'gpt-3.5_{persona}_voor_lprob'] = lprob_voor\n",
    "    results[f'gpt-3.5_{persona}_tegen_lprob'] = lprob_tegen\n",
    "\n",
    "#results.to_csv('gpt3.5_results_persona.csv')\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
